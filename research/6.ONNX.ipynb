{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import re\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "import tf2onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "from typing import List\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "onnx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для \"облегчения\" виртуального окружения исключим необходимость добавлять tensorflow переведя модель в формат onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../predictors/rnn/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model, _ = tf2onnx.convert.from_keras(model)\n",
    "onnx.save(onnx_model, '../predictors/rnn/model.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим результаты конвертации модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (8784, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_true</th>\n",
       "      <th>temperature</th>\n",
       "      <th>datetime</th>\n",
       "      <th>day_off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3385.571934</td>\n",
       "      <td>12.686667</td>\n",
       "      <td>2022-09-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3295.563483</td>\n",
       "      <td>11.673333</td>\n",
       "      <td>2022-09-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    power_true  temperature            datetime  day_off\n",
       "0  3385.571934    12.686667 2022-09-01 00:00:00        0\n",
       "1  3295.563483    11.673333 2022-09-01 01:00:00        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = datetime.strptime('2023-09-01', '%Y-%m-%d')\n",
    "\n",
    "start_time = (date - relativedelta(years=1)).replace(\n",
    "    hour=0,\n",
    "    minute=0,\n",
    "    second=0,\n",
    "    microsecond=0\n",
    ")\n",
    "\n",
    "end_time = date.replace(\n",
    "    hour=23,\n",
    "    minute=0,\n",
    "    second=0,\n",
    "    microsecond=0\n",
    ")\n",
    "\n",
    "predict_time = (date - timedelta(days=1)).replace(\n",
    "    hour=11,\n",
    "    minute=0,\n",
    "    second=0,\n",
    "    microsecond=0\n",
    ")\n",
    "\n",
    "conn = sqlite3.connect('../energy_consumpion.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT\n",
    "        t.power_true,\n",
    "        t.temperature,\n",
    "        t.datetime,\n",
    "        (CASE WHEN\n",
    "            day_off_table.day_off = 1\n",
    "        THEN\n",
    "            1\n",
    "        ELSE\n",
    "            0\n",
    "        END) AS day_off\n",
    "    FROM\n",
    "        consumption_table AS t\n",
    "        LEFT JOIN day_off_table ON DATE(t.datetime) = DATE(day_off_table.datetime)\n",
    "    WHERE\n",
    "        t.datetime >= '{start_time}' AND\n",
    "        t.datetime <= '{end_time}';\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_sql(sql=query, con=conn)\n",
    "conn.close()\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print('data.shape', data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_model(data: pd.DataFrame,\n",
    "              date: datetime) -> np.array:\n",
    "    \"\"\"\n",
    "    Функция делает предсказание потребления элетроэнергии на предстоящие сутки вперед\n",
    "    На вход необходимо передать датафрейм с данными за год\n",
    "    и момент времени, из которого делается предикт\n",
    "    11:00 соответствует полудню... Вот такие пироги...\n",
    "    \"\"\"\n",
    "    def make_data(df       : pd.DataFrame,\n",
    "                  y_lags   : List[int],\n",
    "                  time_freq: List[str],) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Функция, формирующая исходные для предикта от рекурренной нейронной сети\n",
    "        На вход требует:\n",
    "\n",
    "        Датафрейм df, содержащий данные о почасовом потреблении и темпераутре.\n",
    "\n",
    "        Список лагов, по которым будет осуществляться сдвиг во времени назад.\n",
    "        Рекомендуется давать начиная с нуля. Последнее значение не включается.\n",
    "\n",
    "        Список лагов для целевой переменной,\n",
    "        по которым будет осуществляться сдвиг во времени вперед.\n",
    "        Рекомендуется давать начиная с единицы. Последнее значение не включается.\n",
    "\n",
    "        Список частот, по которым необходимо кодировать время и дату.\n",
    "        Доступны: {'hour', 'day_of_year', 'month', 'weekday'}\n",
    "        \"\"\"\n",
    "        time_dict = {'hour'        : 24,\n",
    "                     'day_of_year' : 365.25,\n",
    "                     'month'       : 12,\n",
    "                     'weekday'     : 7}\n",
    "        df.set_index('datetime', inplace=True)\n",
    "\n",
    "        # следующеие фичи нужны для рекуррентного входа\n",
    "\n",
    "        # извлечем тригонометрическую фичу из времени\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            for time_component in time_freq:\n",
    "                df[time_component] = getattr(df.index, time_component)\n",
    "                df[f'{time_component}_sin'] = \\\n",
    "                    np.sin( 2 * np.pi * df[time_component] / time_dict[time_component])\n",
    "                df[f'{time_component}_cos'] = \\\n",
    "                    np.cos( 2 * np.pi * df[time_component] / time_dict[time_component])\n",
    "                df.drop([time_component], axis=1, inplace=True)\n",
    "\n",
    "        # следующеие фичи нужны для полносвязного входа\n",
    "\n",
    "        # присоединим к полносвязному вектору данные о времени,\n",
    "        # назначенном для конкретного предсказания, а также инфу о рабочем/выходном дне\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            for lag in y_lags:\n",
    "                for time_component in time_freq:\n",
    "                    df[f'{time_component}_sin_{lag}'] = df[f'{time_component}_sin'].shift(-lag - 1)\n",
    "                    df[f'{time_component}_cos_{lag}'] = df[f'{time_component}_cos'].shift(-lag - 1)\n",
    "                df[f'day_off_{lag}'] = df['day_off'].shift(-lag - 1)\n",
    "\n",
    "        # присоединим к вектору данные о прошлогоднем потреблении и температуре в этот же час,\n",
    "        # а также сведения о выходном/праздничном дне\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            # создадим временный датафрейм, расширенный на год назад,\n",
    "            # чтобы получить временные сдвиги\n",
    "            temp_df = pd.concat([pd.DataFrame(columns=df.columns,\n",
    "                                              index = pd.date_range(start=df.index[0] - \\\n",
    "                                                                    relativedelta(years=1),\n",
    "                                                                    end=df.index[0],\n",
    "                                                                    freq='H')[:-1]),\n",
    "                                 df[['power_true',\n",
    "                                     'temperature',\n",
    "                                     'day_off']].copy()\n",
    "                                ], axis=0)\n",
    "\n",
    "            for lag in y_lags:\n",
    "                # получим соответствующие лагу индексы\n",
    "                shifted_index = tuple(index - \\\n",
    "                                      relativedelta(years=1) + \\\n",
    "                                        relativedelta(hours=lag + 1) for index in df.index)\n",
    "                # получим значения по временным сдвигам\n",
    "                df[[f'one_hour_consumption_previos_year_{lag}',\n",
    "                    f'one_hour_temperature_previos_year_{lag}',\n",
    "                    f'day_off_previos_year_{lag}']] = \\\n",
    "                        temp_df.loc[pd.DatetimeIndex(shifted_index),\n",
    "                                    ['power_true',\n",
    "                                     'temperature',\n",
    "                                     'day_off']].values\n",
    "\n",
    "        df.rename(columns={'power_true': 'one_hour_consumption',\n",
    "                           'temperature': 'one_hour_temperature'},\n",
    "                  inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    # получим исходные данные для предикта\n",
    "    y_lags=list(range(12, 36))\n",
    "    window_size = 179\n",
    "    time_freq = ['hour', 'day_of_year', 'month', 'weekday']\n",
    "    X = make_data(df=data,\n",
    "                  y_lags=y_lags,\n",
    "                  time_freq=time_freq)\n",
    "\n",
    "    # для дальнейшей обработки определим перечни колонок\n",
    "\n",
    "    # рекуррентный вход\n",
    "    # скаллируемые колонки\n",
    "    RNN_input_scalled_cols = ['one_hour_consumption', 'one_hour_temperature']\n",
    "\n",
    "    # нескаллируемые колонки\n",
    "    RNN_input_not_scalled_regex = r'[a-zA-Z_]+(?:sin|cos|off)\\b'\n",
    "    RNN_input_not_scalled_cols = []\n",
    "\n",
    "    # полносвязный вход\n",
    "    # скаллируемые колонки\n",
    "    Dense_input_scalled_regex = \\\n",
    "        r'(?:one_hour_consumption_previos_year|one_hour_temperature_previos_year)_(\\d+)'\n",
    "    Dense_input_scalled_cols = []\n",
    "\n",
    "    # нескаллируемые колонки\n",
    "    Dense_input_not_scalled_regex = \\\n",
    "        r'[a-zA-Z_]+[(?:sin|cos|off)|(?:day_off_previos_year)]_(?=.*\\d+)'\n",
    "    Dense_input_not_scalled_cols = []\n",
    "\n",
    "    for regex, cols in zip([RNN_input_not_scalled_regex,\n",
    "                            Dense_input_scalled_regex,\n",
    "                            Dense_input_not_scalled_regex,],\n",
    "                           [RNN_input_not_scalled_cols,\n",
    "                            Dense_input_scalled_cols,\n",
    "                            Dense_input_not_scalled_cols,]):\n",
    "        cols.extend([col_name for col_name in X.columns if re.findall(regex, col_name)])\n",
    "\n",
    "    Dense_input_not_scalled_cols = \\\n",
    "        [item for item in Dense_input_not_scalled_cols if item not in Dense_input_scalled_cols]\n",
    "\n",
    "    RNN_input_cols = RNN_input_scalled_cols + RNN_input_not_scalled_cols\n",
    "    Dense_input_cols = Dense_input_scalled_cols + Dense_input_not_scalled_cols\n",
    "\n",
    "    # выделим из полученных данных матрицу для рекуррентного слоя и\n",
    "    # вектор для полносвязного слоя\n",
    "    RNN_input = X.loc[date - timedelta(hours=window_size): date, RNN_input_cols]\n",
    "    Dense_input = pd.DataFrame(X.loc[date, Dense_input_cols]).astype(float).T\n",
    "\n",
    "    with open('../predictors/rnn/scallers.pickle', 'rb') as file:\n",
    "        scaller_RNN, scaller_Dense = pickle.load(file)\n",
    "\n",
    "    # проскаллируем данные\n",
    "    RNN_input.loc[:, RNN_input_scalled_cols] = scaller_RNN \\\n",
    "        .transform(RNN_input.loc[:, RNN_input_scalled_cols] \\\n",
    "                   .values.reshape(-1, len(RNN_input_scalled_cols)))\n",
    "    Dense_input.loc[:, Dense_input_scalled_cols] = scaller_Dense \\\n",
    "        .transform(Dense_input.loc[:, Dense_input_scalled_cols] \\\n",
    "                   .values.reshape(-1, len(Dense_input_scalled_cols)))\n",
    "\n",
    "    # приведем данные к типу np.array\n",
    "    RNN_input = np.array(RNN_input).reshape(-1, *RNN_input.shape)\n",
    "    Dense_input = np.array(Dense_input).reshape(Dense_input.shape)\n",
    "    Input = [RNN_input, Dense_input]\n",
    "\n",
    "    return Input\n",
    "\n",
    "\n",
    "Input = rnn_model(data=data.copy(), date=predict_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 231ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3697.5024, 3551.8816, 3448.0122, 3440.0244, 3470.961 , 3603.1265,\n",
       "        3902.7651, 4280.38  , 4623.8467, 4840.6724, 4913.3574, 4881.355 ,\n",
       "        4873.673 , 4885.9976, 4851.307 , 4799.7026, 4704.1196, 4608.984 ,\n",
       "        4572.611 , 4547.775 , 4586.701 , 4547.1353, 4285.034 , 3937.9934]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../predictors/rnn/model.h5')\n",
    "pred = model.predict(Input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[3697.5024, 3551.882 , 3448.012 , 3440.0242, 3470.9607, 3603.1262,\n",
       "         3902.7654, 4280.3804, 4623.8467, 4840.673 , 4913.3574, 4881.355 ,\n",
       "         4873.6733, 4885.998 , 4851.3076, 4799.7026, 4704.12  , 4608.984 ,\n",
       "         4572.6104, 4547.7744, 4586.7007, 4547.1353, 4285.034 , 3937.994 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = ort.InferenceSession('../predictors/rnn/model.onnx')\n",
    "inputDetails = session.get_inputs()\n",
    "pred = session.run(None, {\n",
    "    inputDetails[0].name: Input[0].astype(np.float32),\n",
    "    inputDetails[1].name: Input[1].astype(np.float32),\n",
    "})\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
